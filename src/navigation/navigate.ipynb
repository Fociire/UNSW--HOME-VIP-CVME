{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following + Waypoint Detection on Jetbot\n",
    "\n",
    "In this notebook we will be combining both optimized regression and classification models into one notebook so that our Jetbot will be able to perform *road following* as well as enable *waypoint detection* at the same time so that it can avoid collisions with obstacles that come on its way in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's execute the code below to transfer the device from CPU memory to the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Road Following**   \n",
    "- Upload the \"*best_steering_model_xy.pth*\" model file obtained from the `road_train_model.ipynb` into this notebooks's directory.\n",
    "\n",
    "### **Waypoint Detection**             \n",
    "- Upload the \"*best_waypoint_model.pth*\" model file obtained from the `waypoint_train_model.ipynb` into this notebooks's directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TRT optimized models by executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model_road = torchvision.models.resnet18(pretrained=False)\n",
    "model_road.fc = torch.nn.Linear(512, 2)\n",
    "model_road.load_state_dict(torch.load('best_steering_model_xy.pth'))\n",
    "\n",
    "model_waypoint = torchvision.models.alexnet(pretrained=False)\n",
    "model_waypoint.classifier[6] = torch.nn.Linear(model_waypoint.classifier[6].in_features, 2)\n",
    "model_waypoint.load_state_dict(torch.load('best_waypoint_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Pre-Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded our models, but there's a slight issue. The format that we trained our models on doesn't exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps:\n",
    "\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "3. Transfer the data from CPU memory to GPU memory\n",
    "4. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "Now, let's start and display our camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224, fps=10)\n",
    "image_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising NurseryHome environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import initialise, NurseryHome, PDDLReader\n",
    "\n",
    "init = initialise.Initialise()\n",
    "init.setup()\n",
    "\n",
    "home = init.home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define some sliders to control the JetBot\n",
    "> **Note**: We have initialized the slider values for best known configurations, however these might not work for your dataset, therefore please increase or decrease the sliders according to your setup and environment\n",
    "\n",
    "1. Speed Control slider: To start your JetBot increase ``speed_control_slider`` \n",
    "2. Steering Gain slider: If you see your JetBot is woblling, you need to reduce ``steering_gain_slider`` till it is smooth\n",
    "3. Steering Bias slider: If you see your JetBot is biased towards extreme right or extreme left side of the track, you should control this slider till JetBot start following line or track in the center.  This accounts for motor biases as well as camera offsets\n",
    "\n",
    "> Note: You should play around above mentioned sliders with lower speed to get smooth JetBot road following behavior.\n",
    "\n",
    "4. Waypoint slider: Display the probability in which there is a waypoint in the front of the Jetbot using the waypoint detection model\n",
    "5. Time for stop slider: To manually set the time for which the jetbot should remain stopped after an object has been removed\n",
    "6. Waypoint threshold slider: To manually set the waypoint detection threshold to stop the Jetbot after a waypoint has been detected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road Following sliders\n",
    "speed_control_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed control')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.04, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_control_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)\n",
    "\n",
    "# Waypoint sliders & buttons\n",
    "waypoint_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, orientation='horizontal', description='waypoint')\n",
    "button_layout = ipywidgets.Layout(width='128px', height='64px')\n",
    "resume_button = ipywidgets.Button(description='resume', button_style='success', layout=button_layout)\n",
    "\n",
    "stop = False\n",
    "def on_resume_clicked():\n",
    "    global stop\n",
    "    stop = False\n",
    "resume_button.on_click(on_resume_clicked)\n",
    "\n",
    "display(ipywidgets.HBox([waypoint_slider, resume_button]))\n",
    "\n",
    "# room number & name\n",
    "room_slider = ipywidgets.IntSlider(min=0, max=home.numRoom()-1, orientation='horizontal', description='waypoint')\n",
    "room_name_widget = ipywidgets.Text(description='room name')\n",
    "\n",
    "curr_room = home.findRoomFromIndex(room_slider.value)\n",
    "def on_room_slider_change(change):\n",
    "    new_index = change['new']\n",
    "    room_name_widget.value = home.findRoomFromIndex(new_index).name\n",
    "    curr_room = home.findRoomFromIndex(new_index)\n",
    "\n",
    "room_name_widget.value = home.findRoomFromIndex(room_slider.value).name\n",
    "room_slider.observe(on_room_slider_change, names='value')\n",
    "\n",
    "display(ipywidgets.HBox([room_slider, room_name_widget]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalising robot and PDDL reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Robot as RobotEntity\n",
    "\n",
    "robot_entity = RobotEntity.Robot(home, curr_room)\n",
    "pddlReader = PDDLReader.PDDLReader(robot_entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes. This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network models for Road following and Waypoint Detection\n",
    "3. Check an if statements which would allow the Jetbot to perform road following and stop whenever a waypoint has been detected \n",
    "4. Compute the approximate steering value\n",
    "5. Control the motors using proportional / derivative control (PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "clocwise = True\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, speed_value\n",
    "    global blocked_slider, robot, stop\n",
    "    global clocwise\n",
    "\n",
    "    image = change['new']\n",
    "    image = preprocess(image)\n",
    "    \n",
    "    # WAYPOINT MODEL\n",
    "    model_waypoint.cuda()\n",
    "    y_w = model_waypoint(image.float())\n",
    "    y_w = F.softmax(y_w, dim=1)\n",
    "    prob_waypoint = float(y_w.flatten()[0])\n",
    "    waypoint_slider.value = prob_waypoint\n",
    "    \n",
    "    # waypoint reached\n",
    "    if prob_waypoint > 0.5:\n",
    "        stop = True\n",
    "        print(\"WAYPOINT REACHED\")\n",
    "        if clocwise:\n",
    "            room_slider.value += 1\n",
    "        else:\n",
    "            room_slider.value -= 1\n",
    "    \n",
    "    # stop\n",
    "    if stop:\n",
    "        speed_slider.value = 0\n",
    "    else:\n",
    "        speed_slider.value = speed_control_slider.value\n",
    "    \n",
    "    # ROAD FOLLOWING MODEL\n",
    "    xy = model_road(image).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing.\n",
    "\n",
    "We accomplish that with the observe function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">WARNING: This code will move the robot!! Please make sure your robot has clearance and it is on Lego or Track you have collected data on. The road follower and collision avoider should work, but the neural network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame. \n",
    "\n",
    "You can now place JetBot on  Lego or Track you have collected data on and see whether it can follow the track and avoid collisions effectively.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetbot-labs",
   "language": "python",
   "name": "jetbot-labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
