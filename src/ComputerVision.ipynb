{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a deployment on pre-trained model to recognize objects with JetBot's camera. (For Specs plz refer to the link in readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, pretrained resNet is chosen for a higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True).eval()\n",
    "\n",
    "# Create a transform to preprocess camera images and tailor it to suitable size\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object recognition function is the key, and the result can be used for the ethics team to rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_objects(image):\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "    # Get the predicted class\n",
    "    _, predicted = outputs.max(1)\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is for a neat user-friendly interface to show the live stream and predicted items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpeg', width=224, height=224)\n",
    "label_widget = widgets.Text(description='Detected', width=200)\n",
    "\n",
    "def update(change):\n",
    "    image = np.array(change['new'])\n",
    "    class_index = recognize_objects(image)\n",
    "    \n",
    "    # Here, you might convert class_index to a string using some mapping\n",
    "    # depending on the dataset the model was trained on.\n",
    "    \n",
    "    label_widget.value = str(class_index)\n",
    "    image_widget.value = cv2.imencode('.jpg', cv2.cvtColor(image, cv2.COLOR_BGR2RGB))[1].tobytes()\n",
    "\n",
    "camera.observe(update, names='value')\n",
    "\n",
    "display(image_widget, label_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut down the camera and robot properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
